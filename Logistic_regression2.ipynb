{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. You are provided the titanic dataset. Load the dataset and perform splitting into training and test sets with 70:30 ratio randomly using test train split.\n",
    "2. Use the Logistic regression created from scratch (from the prev question) in this question as well.\n",
    "3. Data cleaning plays a major role in this question. Report all the methods used by you in the ipynb.\n",
    "\n",
    "--> \n",
    "\n",
    "i. Check for missing values\n",
    "\n",
    "ii. Drop Columns & Handle missing values\n",
    "\n",
    "iii. Create dummies for categorical features\n",
    "\n",
    "you are free to perform other data cleaning to improve your results.\n",
    "\n",
    "\n",
    "\n",
    "4. Report accuracy score, Confusion matrix, heat map, classifiaction report and any other metrics you feel useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset link : \n",
    "https://iiitaphyd-my.sharepoint.com/:f:/g/personal/apurva_jadhav_students_iiit_ac_in/Eictt5_qmoxNqezgQQiMWeIBph4sxlfA6jWAJNPnV2SF9Q?e=mQmYN0 \n",
    "\n",
    "(titanic.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('Logistic_Regression_dataset/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       " 0         3    1  22.0      1      0   7.2500       0.0\n",
       " 1         1    0  38.0      1      0  71.2833       1.0\n",
       " 2         3    0  26.0      0      0   7.9250       0.0\n",
       " 3         1    0  35.0      1      0  53.1000       0.0\n",
       " 4         3    1  35.0      0      0   8.0500       0.0\n",
       " ..      ...  ...   ...    ...    ...      ...       ...\n",
       " 886       2    1  27.0      0      0  13.0000       0.0\n",
       " 887       1    0  19.0      0      0  30.0000       0.0\n",
       " 888       3    0   NaN      1      2  23.4500       0.0\n",
       " 889       1    1  26.0      0      0  30.0000       1.0\n",
       " 890       3    1  32.0      0      0   7.7500       2.0\n",
       " \n",
       " [891 rows x 7 columns],\n",
       " 0      0\n",
       " 1      1\n",
       " 2      1\n",
       " 3      1\n",
       " 4      0\n",
       "       ..\n",
       " 886    0\n",
       " 887    1\n",
       " 888    0\n",
       " 889    1\n",
       " 890    0\n",
       " Name: Survived, Length: 891, dtype: int64)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n",
    "x_l = data.drop(['Survived','Ticket','Cabin','Name','PassengerId'],axis=1)\n",
    "y_l = data['Survived']\n",
    "\n",
    "sex_dict = {'female':0,'male':1}\n",
    "x_l['Sex'] = x_l.Sex.map(sex_dict)\n",
    "\n",
    "emb_dict = {'S':0,'C':1,'Q':2}\n",
    "x_l['Embarked'] = x_l.Embarked.map(emb_dict)\n",
    "\n",
    "x_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.275     , ..., 0.        , 0.01415106,\n",
       "        0.        ],\n",
       "       [0.33333333, 0.        , 0.475     , ..., 0.        , 0.13913574,\n",
       "        0.5       ],\n",
       "       [1.        , 0.        , 0.325     , ..., 0.        , 0.01546857,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.        , 0.        , ..., 0.33333333, 0.04577135,\n",
       "        0.        ],\n",
       "       [0.33333333, 1.        , 0.325     , ..., 0.        , 0.0585561 ,\n",
       "        0.5       ],\n",
       "       [1.        , 1.        , 0.4       , ..., 0.        , 0.01512699,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_l = x_l.to_numpy()\n",
    "y_l = y_l.to_numpy()\n",
    "x_l = np.nan_to_num(x_l)\n",
    "\n",
    "x_l = x_l / x_l.max(axis=0)\n",
    "x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(x_l, y_l.reshape(y_l.shape[0]), test_size=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def diff_g(w,x,y):\n",
    "    y_minus_sigmoid_wtx = sigmoid(np.dot(x,w)) - y\n",
    "    return np.dot(x.T,y_minus_sigmoid_wtx)\n",
    "\n",
    "def gradient_descent(x,y, num_iterations = 10000, learning_rate = 0.01):\n",
    "    w = np.zeros(x.shape[1])\n",
    "    for i in range(num_iterations):\n",
    "        w = w - (learning_rate * diff_g(w,x,y))\n",
    "    return w\n",
    "\n",
    "def get_w_after_training(x,y):\n",
    "    x = np.c_[x, np.ones(x.shape[0])]\n",
    "    return gradient_descent(x,y)\n",
    "\n",
    "def predict(w,x):\n",
    "    x = np.c_[x, np.ones(x.shape[0])]\n",
    "#     print(np.dot(w.T,x.T))\n",
    "    sigm = sigmoid(np.dot(w.T,x.T))\n",
    "    sigm[sigm > 0.5] = 1\n",
    "    sigm[sigm <= 0.5] = 0\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.94575501, -2.80066812, -1.57976994, -3.02128797,  0.13927092,\n",
       "        1.20630018,  0.49361807,  3.97373284])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = get_w_after_training(trainX,trainy)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict(w,testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  77.98507462686567\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = (testy==predicted).mean()*100\n",
    "print(\"Accuracy Score = \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "\n",
      " [[139  32]\n",
      " [ 27  70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Confusion Matrix :\\n\\n\",confusion_matrix(testy, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       171\n",
      "           1       0.69      0.72      0.70        97\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.76      0.77      0.76       268\n",
      "weighted avg       0.78      0.78      0.78       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report :\\n\\n\",classification_report(testy, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
